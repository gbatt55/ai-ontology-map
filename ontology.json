{
  "meta": {
    "version": "0.1",
    "description": "AI supply chain ontology (7-layer model).",
    "last_updated": "2025-11-15"
  },
  "layers": [
    { "id": 1, "name": "Physical Power & Electro-Industrial Base" },
    { "id": 2, "name": "Compute Fabric (Silicon, Packaging, Systems)" },
    { "id": 3, "name": "Cluster OS & Distributed Systems" },
    { "id": 4, "name": "Foundation Model Training Layer" },
    { "id": 5, "name": "Model Serving, Routing & Orchestration" },
    { "id": 6, "name": "Applications & Domain Workflows" },
    { "id": 7, "name": "Organizational & Societal Embedding" }
  ],
  "nodes": [
    {
      "id": "nvidia",
      "name": "NVIDIA",
      "layer": 2,
      "type": "company",
      "description": "GPU and accelerator vendor; CUDA ecosystem; HBM-hungry training and inference hardware."
    },
    {
      "id": "amd",
      "name": "AMD",
      "layer": 2,
      "type": "company",
      "description": "Competing accelerators (MI series); CPU + GPU; alternative to NVIDIA in some clusters."
    },
    {
      "id": "intel",
      "name": "Intel",
      "layer": 2,
      "type": "company",
      "description": "CPUs, Gaudi accelerators; fabs; attempting relevance in AI compute."
    },
    {
      "id": "tsmc",
      "name": "TSMC",
      "layer": 2,
      "type": "company",
      "description": "Advanced foundry and packaging (CoWoS); chokepoint for leading-edge AI silicon."
    },
    {
      "id": "sk_hynix",
      "name": "SK hynix",
      "layer": 2,
      "type": "company",
      "description": "Leading HBM supplier; memory bottleneck for AI accelerators."
    },
    {
      "id": "samsung",
      "name": "Samsung",
      "layer": 2,
      "type": "company",
      "description": "Memory + foundry; player in HBM and advanced nodes."
    },
    {
      "id": "hbm",
      "name": "HBM",
      "layer": 2,
      "type": "technology",
      "description": "High Bandwidth Memory; critical resource for AI accelerator performance."
    },
    {
      "id": "cowos",
      "name": "CoWoS",
      "layer": 2,
      "type": "technology",
      "description": "Advanced 2.5D/3D chip packaging used for high-end AI accelerators."
    },
    {
      "id": "microsoft",
      "name": "Microsoft",
      "layer": 7,
      "type": "company",
      "description": "Hyperscaler; Azure cloud; deep integration with enterprise and government."
    },
    {
      "id": "azure",
      "name": "Azure",
      "layer": 3,
      "type": "platform",
      "description": "Microsoft cloud; cluster OS, orchestration, and infra for AI training and serving."
    },
    {
      "id": "openai",
      "name": "OpenAI",
      "layer": 4,
      "type": "company",
      "description": "Frontier model developer; tightly coupled to Azure/Microsoft."
    },
    {
      "id": "google",
      "name": "Google",
      "layer": 2,
      "type": "company",
      "description": "TPUs, Google Cloud, internal models (Gemini). Vertical integration across layers."
    },
    {
      "id": "meta",
      "name": "Meta",
      "layer": 4,
      "type": "company",
      "description": "Llama open-weight model family; heavy internal infra; social + ads embedding."
    },
    {
      "id": "aws",
      "name": "AWS",
      "layer": 3,
      "type": "company",
      "description": "Hyperscale cloud; Trainium/Inferentia; strong infra + enterprise presence."
    },
    {
      "id": "xai",
      "name": "xAI",
      "layer": 4,
      "type": "company",
      "description": "Frontier-ish models and inference focus; aspiring competitor in model layer."
    },
    {
      "id": "cuda",
      "name": "CUDA",
      "layer": 3,
      "type": "technology",
      "description": "NVIDIA software stack; developer lock-in; key part of NVIDIA moat."
    },
    {
      "id": "enterprise_apps",
      "name": "Enterprise AI Apps",
      "layer": 6,
      "type": "concept",
      "description": "Vertical copilots, agents, and workflow tools embedded in enterprises."
    },
    {
      "id": "grid_power",
      "name": "Grid Power & Datacenter Energy",
      "layer": 1,
      "type": "infrastructure",
      "description": "Electricity supply, transmission, and datacenter siting constraints."
    },
    {
      "id": "regulators_us",
      "name": "US Regulators & Policy",
      "layer": 7,
      "type": "institution",
      "description": "National industrial policy, export controls, and AI-related regulation."
    }
  ],
  "edges": [
    {
      "source": "nvidia",
      "target": "tsmc",
      "type": "dependency",
      "weight": 0.95,
      "notes": "Leading-edge nodes + CoWoS packaging; severe capacity dependence."
    },
    {
      "source": "nvidia",
      "target": "sk_hynix",
      "type": "dependency",
      "weight": 0.9,
      "notes": "HBM supply is a key bottleneck."
    },
    {
      "source": "nvidia",
      "target": "amd",
      "type": "competition",
      "weight": 0.7,
      "notes": "Accelerator competition (MI series vs H100/B100 lines)."
    },
    {
      "source": "nvidia",
      "target": "intel",
      "type": "competition",
      "weight": 0.4,
      "notes": "Competing accelerators and foundry ambitions, but weaker near-term."
    },
    {
      "source": "openai",
      "target": "azure",
      "type": "dependency",
      "weight": 0.95,
      "notes": "Frontier training and serving run primarily on Azure."
    },
    {
      "source": "microsoft",
      "target": "openai",
      "type": "leverage",
      "weight": 0.85,
      "notes": "Capital, distribution, integration leverage over OpenAI."
    },
    {
      "source": "google",
      "target": "nvidia",
      "type": "competition",
      "weight": 0.5,
      "notes": "TPUs compete with NVIDIA GPUs in some internal and external workloads."
    },
    {
      "source": "aws",
      "target": "nvidia",
      "type": "dependency",
      "weight": 0.7,
      "notes": "AWS depends on NVIDIA hardware while also pushing Trainium/Inferentia."
    },
    {
      "source": "aws",
      "target": "google",
      "type": "competition",
      "weight": 0.8,
      "notes": "Cloud and AI infra competition."
    },
    {
      "source": "aws",
      "target": "microsoft",
      "type": "competition",
      "weight": 0.9,
      "notes": "Primary hyperscaler competitors."
    },
    {
      "source": "grid_power",
      "target": "azure",
      "type": "dependency",
      "weight": 0.85,
      "notes": "Datacenters constrained by grid capacity and siting."
    },
    {
      "source": "grid_power",
      "target": "aws",
      "type": "dependency",
      "weight": 0.85,
      "notes": "Same as above for AWS data centers."
    },
    {
      "source": "grid_power",
      "target": "google",
      "type": "dependency",
      "weight": 0.85,
      "notes": "Same as above for Google Cloud."
    },
    {
      "source": "enterprise_apps",
      "target": "openai",
      "type": "dependency",
      "weight": 0.6,
      "notes": "Many enterprise apps rely (directly or indirectly) on OpenAI models."
    },
    {
      "source": "enterprise_apps",
      "target": "microsoft",
      "type": "dependency",
      "weight": 0.7,
      "notes": "Enterprise AI apps often distributed via Microsoft ecosystem (Office, Azure, etc.)."
    },
    {
      "source": "regulators_us",
      "target": "nvidia",
      "type": "leverage",
      "weight": 0.6,
      "notes": "Export controls and AI policy can affect NVIDIA's business."
    },
    {
      "source": "regulators_us",
      "target": "tsmc",
      "type": "leverage",
      "weight": 0.5,
      "notes": "Policy influences advanced node access and export destinations."
    },
    {
      "source": "xai",
      "target": "openai",
      "type": "competition",
      "weight": 0.5,
      "notes": "Competing for model mindshare and benchmarks."
    }
  ]
}
